## PostgreSQL 优化case - where A字段范围 order by B字段排序 limit x  
    
### 作者    
digoal    
    
### 日期    
2020-07-10  
    
### 标签    
PostgreSQL , 排序 , 范围过滤 , 分页    
    
----    
    
## 背景    
优化的目标是尽量减少计算, IO, filter, recheck等.  
  
比如以下查询, 乍看一下难以优化  
  
```  
select * from tbl where ts between x and y   
order by z limit x;  
```  
  
1、查询条件ts字段是范围, 跨度大, 满足的结果很多, 按z排序需要显示的sort大量记录.  
  
2、排序按z字段, z顺序返回时, 满足ts条件的记录都很靠后, 需要大量filter.  
  
因为ts和z是两个字段, 没法使用index(ts,z)或者index(z,ts)来做到完全走索引就可以.  
  
### 优化  
首先了解背景  
  
z为pk,   
  
z和ts具有线性相关性(正相关或负相关), 并且都有方向性, 例如递增, 或者递减. 因此这个查询可以进行修改.  
  
```  
select * from tbl where ts between x and y   
and z ?   
order by z limit x;  
```  
  
每次查询n条, 逐次推进, 将所有满足ts between x and y条件的记录分批查出来并处理.  
  
优化思路:   
  
1、补充z的条件作为初始条件, 这样不需要过多的过滤.  
  
```  
select min(z), max(z) into id1,id2 from tbl where ts between x and y;  
  
select * from tbl where ts between x and y   
and z>=id1 and z<=id2   
order by z desc limit x;   
  
min(z) into id2  
```  
  
2、每次查出来的一批记录, 把id传进去作为新的条件, 那么每次都不需要过多的过滤.  
  
```  
select * from tbl where ts between x and y and z<id2 order by z desc limit x;   
  
min(z) into id2  
```  
  
## 例子  
```  
create table tbl (id int primary key, info text, crt_time timestamp);  
insert into tbl select generate_series(1,100000000), md5(random()::text) , clock_timestamp();  
```  
  
原始sql  
  
```  
postgres=# select min(crt_time), max(crt_time) from tbl;  
            min             |            max               
----------------------------+----------------------------  
 2020-07-10 14:04:46.600332 | 2020-07-10 14:08:06.737822  
(1 row)  
  
select * from tbl where crt_time between '2020-07-10 14:05:45' and '2020-07-10 14:07:00'  
order by id limit 100;  
  
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from tbl where crt_time between '2020-07-10 14:05:45' and '2020-07-10 14:07:00'  
order by id limit 100;  
                                                                           QUERY PLAN                                                                              
-----------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Limit  (cost=0.57..9.22 rows=100 width=45) (actual time=4003.046..4003.071 rows=100 loops=1)  
   Output: id, info, crt_time  
   Buffers: shared hit=288650 read=63193  
   ->  Index Scan using tbl_pkey on public.tbl  (cost=0.57..3208769.85 rows=37078282 width=45) (actual time=4003.045..4003.062 rows=100 loops=1)  
         Output: id, info, crt_time  
         Filter: ((tbl.crt_time >= '2020-07-10 14:05:45'::timestamp without time zone) AND (tbl.crt_time <= '2020-07-10 14:07:00'::timestamp without time zone))  
         Rows Removed by Filter: 29130419  
         Buffers: shared hit=288650 read=63193  
 Planning Time: 0.093 ms  
 Execution Time: 4003.096 ms  
(10 rows)  
  
-- 大量filter  
```  
  
优化初始sql  
  
```  
select min(id),max(id) from tbl where crt_time between '2020-07-10 14:05:45' and '2020-07-10 14:07:00';  
   min    |   max      
----------+----------  
 29130420 | 66423729  
(1 row)  
  
select * from tbl where crt_time between '2020-07-10 14:05:45' and '2020-07-10 14:07:00'  
and id>=29130420 and id<=66423729   
order by id desc limit 100;   
  
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from tbl where crt_time between '2020-07-10 14:05:45' and '2020-07-10 14:07:00'  
and id>=29130420 and id<=66423729   
order by id desc limit 100;   
                                                                           QUERY PLAN                                                                              
-----------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Limit  (cost=0.57..10.57 rows=100 width=45) (actual time=0.022..0.051 rows=100 loops=1)  
   Output: id, info, crt_time  
   Buffers: shared hit=6  
   ->  Index Scan Backward using tbl_pkey on public.tbl  (cost=0.57..1374883.82 rows=13745329 width=45) (actual time=0.021..0.043 rows=100 loops=1)  
         Output: id, info, crt_time  
         Index Cond: ((tbl.id >= 29130420) AND (tbl.id <= 66423729))  
         Filter: ((tbl.crt_time >= '2020-07-10 14:05:45'::timestamp without time zone) AND (tbl.crt_time <= '2020-07-10 14:07:00'::timestamp without time zone))  
         Buffers: shared hit=6  
 Planning Time: 0.121 ms  
 Execution Time: 0.068 ms  
(10 rows)  
  
```  
  
优化分批查询sql  
  
```  
select * from tbl where   
crt_time between '2020-07-10 14:05:45' and '2020-07-10 14:07:00'  
and id<66423630  
order by id desc limit 100;   
  
select * from tbl where   
crt_time between '2020-07-10 14:05:45' and '2020-07-10 14:07:00'  
and id<66423530  
order by id desc limit 100;   
```  
  
```  
                                                                           QUERY PLAN                                                                              
-----------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Limit  (cost=0.57..9.90 rows=100 width=45) (actual time=0.042..0.074 rows=100 loops=1)  
   Output: id, info, crt_time  
   Buffers: shared hit=8  
   ->  Index Scan Backward using tbl_pkey on public.tbl  (cost=0.57..2298576.97 rows=24640916 width=45) (actual time=0.041..0.065 rows=100 loops=1)  
         Output: id, info, crt_time  
         Index Cond: (tbl.id < 66423530)  
         Filter: ((tbl.crt_time >= '2020-07-10 14:05:45'::timestamp without time zone) AND (tbl.crt_time <= '2020-07-10 14:07:00'::timestamp without time zone))  
         Buffers: shared hit=8  
 Planning Time: 0.107 ms  
 Execution Time: 0.097 ms  
(10 rows)  
```  
  
性能提升40000倍.  
    
### case2:  
  
假设查询都是按天的, 那么可以把event_time从范围匹配变成分散匹配.  从而用上联合索引.  
  
```  
create unlogged table a (id int, event_time timestamp, crt_time timestamp, info text) ;  
  
insert into a select id, clock_timestamp()+((id+random()*100)||' second')::interval, clock_timestamp()+((id+random()*100)||' second')::interval, (random()*100)::int::text  
from generate_series(1,10000000) id;  
  
select min(event_time), max(event_time), min(crt_time), max(crt_time) from a;    
  
            min             |            max             |            min             |            max               
----------------------------+----------------------------+----------------------------+----------------------------  
 2022-08-22 17:11:47.322564 | 2022-12-16 11:00:04.718084 | 2022-08-22 17:11:43.500185 | 2022-12-16 11:00:04.851408  
(1 row)  
  
  
  
create index idx_a on a (info,crt_time);  
  
select * from a where info='2' and event_time between '2022-08-25' and '2022-08-26' order by crt_time desc limit 10;  
  
  
postgres=# explain (analyze, verbose,timing,costs,buffers) select * from a where info='2' and event_time between '2022-08-25' and '2022-08-26' order by crt_time desc limit 10;  
                                                                           QUERY PLAN                                                                              
-----------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Limit  (cost=0.43..2888.10 rows=10 width=22) (actual time=187.762..187.782 rows=10 loops=1)  
   Output: id, event_time, crt_time, info  
   Buffers: shared hit=3416 read=53514  
   ->  Index Scan Backward using idx_a on public.a  (cost=0.43..244296.61 rows=846 width=22) (actual time=187.760..187.778 rows=10 loops=1)  
         Output: id, event_time, crt_time, info  
         Index Cond: (a.info = '2'::text)  
         Filter: ((a.event_time >= '2022-08-25 00:00:00'::timestamp without time zone) AND (a.event_time <= '2022-08-26 00:00:00'::timestamp without time zone))  
         Rows Removed by Filter: 96982  
         Buffers: shared hit=3416 read=53514  
 Planning Time: 0.179 ms  
 Execution Time: 187.810 ms  
(11 rows)  
  
Time: 189.837 ms  
```  
  
假设查询都是按天的, 那么可以把event_time从范围匹配变成分散匹配.  从而用上联合索引, 精准过滤, 提升性能.  
  
```  
create index idx_a1 on a (info,date(event_time),crt_time);  
  
postgres=# explain (analyze, verbose,timing,costs,buffers) select * from a where info='2' and date(event_time) in ('2022-08-25') order by crt_time desc limit 10;  
                                                              QUERY PLAN                                                                 
---------------------------------------------------------------------------------------------------------------------------------------  
 Limit  (cost=0.43..40.71 rows=10 width=22) (actual time=0.029..0.038 rows=10 loops=1)  
   Output: id, event_time, crt_time, info  
   Buffers: shared hit=9  
   ->  Index Scan Backward using idx_a1 on public.a  (cost=0.43..2046.57 rows=508 width=22) (actual time=0.027..0.035 rows=10 loops=1)  
         Output: id, event_time, crt_time, info  
         Index Cond: ((a.info = '2'::text) AND (date(a.event_time) = '2022-08-25'::date))  
         Buffers: shared hit=9  
 Planning Time: 0.125 ms  
 Execution Time: 0.056 ms  
(9 rows)  
  
Time: 0.475 ms  
```  
       
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
