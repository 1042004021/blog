## zpool add top-level vdev; attach, detach, offline, online, replace vdev;  
                                                                                                                                                                   
### 作者                                                                                                                                                               
digoal                                                                                                                                                                 
                                                                                                                                                             
### 日期                                                                                                                                                                                
2014-05-27                                                                                                                                                       
                                                                                                                                                              
### 标签                                                                                                                                                             
PostgreSQL , Linux , ZFS                                                                                                                                                           
                                                                                                                                                                                               
----                                                                                                                                                                       
                                                                                                                                                                                                           
## 背景           
zpool允许我们动态的添加vdev, 这个我们已经在上一篇BLOG中介绍过.  
  
http://blog.163.com/digoal@126/blog/static/163877040201442731413803/  
  
```  
如添加spare  
[root@db-172-16-3-150 ssd1]# zpool add zpp spare /ssd1/zfs.6  
[root@db-172-16-3-150 ssd1]# zpool status zpp  
  pool: zpp  
 state: ONLINE  
  scan: none requested  
config:  
  
        NAME             STATE     READ WRITE CKSUM  
        zpp              ONLINE       0     0     0  
          mirror-0       ONLINE       0     0     0  
            /ssd1/zfs.1  ONLINE       0     0     0  
            /ssd1/zfs.2  ONLINE       0     0     0  
          raidz1-1       ONLINE       0     0     0  
            /ssd1/zfs.3  ONLINE       0     0     0  
            /ssd1/zfs.4  ONLINE       0     0     0  
            /ssd1/zfs.5  ONLINE       0     0     0  
        spares  
          /ssd1/zfs.6    AVAIL  
这里继续介绍一下mirror设备或raidz设备中的一些vdev 的操作.  
例如mirror设备允许attach和detach  
[root@db-172-16-3-150 ssd1]# zpool attach zpp /ssd1/zfs.2 /ssd1/zfs.1  
[root@db-172-16-3-150 ssd1]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.2   ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
  
[root@db-172-16-3-150 ssd1]# zpool detach zpp /ssd1/zfs.2   
[root@db-172-16-3-150 ssd1]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
  
raidz的设备不允许detach和attach  
[root@db-172-16-3-150 ssd1]# zpool detach zpp /ssd1/zfs.5  
cannot detach /ssd1/zfs.5: only applicable to mirror and replacing vdevs  
[root@db-172-16-3-150 man8]# zpool attach zpp /ssd1/zfs.5 /ssd1/zfs.2  
cannot attach /ssd1/zfs.2 to /ssd1/zfs.5: can only attach to mirrors and top-level disks  
  
单设备也允许attach, 变成mirror设备.  
[root@db-172-16-3-150 test]# zpool status zpp  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          /ssd1/zfs.1     ONLINE       0     0     0  
[root@db-172-16-3-150 test]# zpool attach zpp /ssd1/zfs.1 /ssd1/zfs.11  
绑定后变成了mirror设备.  
[root@db-172-16-3-150 test]# zpool status zpp  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
  
offline则可以针对有冗余的设备的离线.  
对raidz和mirror都可以这么做, 但是必须确保至少数据还是可用的, 例如raidz1可以offline1个设备  
[root@db-172-16-3-150 man8]# zpool offline zpp /ssd1/zfs.5  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: DEGRADED  
status: One or more devices has been taken offline by the administrator.  
        Sufficient replicas exist for the pool to continue functioning in a  
        degraded state.  
action: Online the device using 'zpool online' or replace the device with  
        'zpool replace'.  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               DEGRADED     0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        DEGRADED     0     0     0  
            /ssd1/zfs.5   OFFLINE      0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
[root@db-172-16-3-150 man8]# zpool offline zpp /ssd1/zfs.6  
cannot offline /ssd1/zfs.6: no valid replicas  
[root@db-172-16-3-150 man8]# zpool offline zpp /ssd1/zfs.10  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: DEGRADED  
status: One or more devices has been taken offline by the administrator.  
        Sufficient replicas exist for the pool to continue functioning in a  
        degraded state.  
action: Online the device using 'zpool online' or replace the device with  
        'zpool replace'.  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               DEGRADED     0     0     0  
          mirror-0        DEGRADED     0     0     0  
            /ssd1/zfs.10  OFFLINE      0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        DEGRADED     0     0     0  
            /ssd1/zfs.5   OFFLINE      0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
  
启用  
[root@db-172-16-3-150 man8]# zpool online zpp /ssd1/zfs.10  
[root@db-172-16-3-150 man8]# zpool online zpp /ssd1/zfs.5  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 2K in 0h0m with 0 errors on Tue May 27 15:58:23 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        ONLINE       0     0     0  
            /ssd1/zfs.5   ONLINE       0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
  
replace 一般用于坏掉的设备的替换.  
[root@db-172-16-3-150 man8]# zpool detach zpp /ssd1/zfs.11  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 2K in 0h0m with 0 errors on Tue May 27 15:58:23 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        ONLINE       0     0     0  
            /ssd1/zfs.5   ONLINE       0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          /ssd1/zfs.12    ONLINE       0     0     0  
[root@db-172-16-3-150 ssd1]# zpool replace zpp /ssd1/zfs.1 /ssd1/zfs.12  
[root@db-172-16-3-150 ssd1]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 1.26M in 0h0m with 0 errors on Tue May 27 15:37:52 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.2   ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        ONLINE       0     0     0  
            /ssd1/zfs.5   ONLINE       0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
```  
      
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [1 任意维度实时圈人](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [2 时序数据实时处理](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [3 时间、空间、业务 多维数据实时透视](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [4 独立事件相关性分析](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [5 海量关系实时图式搜索](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [6 社交业务案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [7 流式数据实时处理案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [8 IoT 物联网, 时序](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [9 全文检索](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [10 模糊、正则 查询案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [11 图像识别](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [12 向量相似检索](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [13 数据清洗、采样、脱敏、批处理、合并](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [14 GIS 地理信息空间数据应用](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [15 金融业务](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [16 异步消息应用案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [17 海量数据 冷热分离](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [18 倒排索引案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [19 海量数据OLAP处理应用](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's 趣味入口 - 努力成为灯塔, 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![德哥的微信 / digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [1 任意维度实时圈人](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [2 时序数据实时处理](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [3 时间、空间、业务 多维数据实时透视](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [4 独立事件相关性分析](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [5 海量关系实时图式搜索](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [6 社交业务案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [7 流式数据实时处理案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [8 IoT 物联网, 时序](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [9 全文检索](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [10 模糊、正则 查询案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [11 图像识别](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [12 向量相似检索](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [13 数据清洗、采样、脱敏、批处理、合并](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [14 GIS 地理信息空间数据应用](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [15 金融业务](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [16 异步消息应用案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [17 海量数据 冷热分离](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [18 倒排索引案例](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
- [19 海量数据OLAP处理应用](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
