## PostgreSQL 大数据场景存储生态: apache arrow - by pg-strom               
                                                                                    
### 作者                                                              
digoal                                                              
                                                              
### 日期                                                              
2023-03-19                                                          
                                                              
### 标签                                                              
PostgreSQL , PolarDB , duckdb , 存储 , parquet , arrow , gpu , cuda , 大数据 , pg-strom                                
                                                              
----                                                              
                                                              
## 背景     
Apache Arrow is a data format of structured data to save in columnar-form and to exchange other applications. Some applications for big-data processing support the format, and it is easy for self-developed applications to use Apache Arrow format since they provides libraries for major programming languages like C,C++ or Python.  
  
Apache Arrow format file internally contains Schema portion to define data structure, and one or more RecordBatch to save columnar-data based on the schema definition. For data types, it supports integers, strint (variable-length), date/time types and so on. Indivisual columnar data has its internal representation according to the data types.  
  
PostgreSQL pg-strom 是计算加速插件, 利用GPU的计算能力. 计算加速通常出现在大数据计算场景, 所以可以说pg-strom把单机版的PG扩展到了大数据场景, 但是光有计算加速还不够, 存储结构也要变化, 才能应对好大数据场景, 也就是接入大数据场景常用的存储生态. arrow就是适合大数据场景的存储引擎之一, 很多大数据计算产品都支持arrow(例如spark, pandas, drill, impala, hbase, kudu, cassandra, parquet等).   
  
pg-strom 贡献的pg2arrow插件可以将PG的数据转成arrow列存储文件. arrow_fdw则可以让PG通过外部表的接口读写arrow格式的列存储文件.   
  
通过arrow的支持, 使得PG融入到了大数据生态中.    
  
## pg2arrow  
https://github.com/heterodb/pg2arrow  
  
```  
$ git clone https://github.com/heterodb/pg-strom.git  
$ cd pg-strom/arrow-tools  
$ make  
$ sudo make install  
$ pg2arrow --help  
Usage:  
  pg2arrow [OPTION] [database] [username]  
  
General options:  
  -d, --dbname=DBNAME   Database name to connect to  
  -c, --command=COMMAND SQL command to run  
  -t, --table=TABLENAME Equivalent to '-c SELECT * FROM TABLENAME'  
      (-c and -t are exclusive, either of them must be given)  
      --inner-join=SUB_COMMAND  
      --outer-join=SUB_COMMAND  
  -o, --output=FILENAME result file in Apache Arrow format  
      --append=FILENAME result Apache Arrow file to be appended  
      (--output and --append are exclusive. If neither of them  
       are given, it creates a temporary file.)  
  -S, --stat[=COLUMNS] embeds min/max statistics for each record batch  
                       COLUMNS is a comma-separated list of the target  
                       columns if partially enabled.  
  
Arrow format options:  
  -s, --segment-size=SIZE size of record batch for each  
  
Connection options:  
  -h, --host=HOSTNAME  database server host  
  -p, --port=PORT      database server port  
  -u, --user=USERNAME  database user name  
  -w, --no-password    never prompt for password  
  -W, --password       force password prompt  
  
Other options:  
      --dump=FILENAME  dump information of arrow file  
      --progress       shows progress of the job  
      --set=NAME:VALUE config option to set before SQL execution  
      --help           shows this message  
  
Report bugs to <pgstrom@heterodb.com>.  
```  
  
https://github.com/heterodb/pg-strom/wiki/803:-Data-exchange-with-SQL-databases-over-Apache-Arrow  
  
`pg2arrow` is a utility command to dump PostgreSQL contents as Apache Arrow files. Below is the simplest example to dump the table table0 in the database postgres to `/path/to/file0.arrow`.  
  
```  
$ pg2arrow -d postgres -c 'SELECT * FROM table0' -o /path/to/file0.arrow  
```  
  
You can supply more complicated query according to the `-c` option. This example tries to cast id to bigint, and fetch 8 charactors from the head of x.  
  
```  
$ pg2arrow -d postgres -c 'SELECT id::bigint,substring(x from 1 for 8) FROM table0' -o /dev/shm/file0.arrow  
```  
  
Not only creation of a new file, you can expand an existing Apache Arrow file using `--append` instead of `-o` option. In this case, the supplied query by `-c` option must be compatible to the schema definitions of the target file.  
  
```  
$ pg2arrow -d postgres -c 'SELECT * FROM table0' --append /path/to/file0.arrow  
```  
  
## arrow_fdw  
  
https://heterodb.github.io/pg-strom/arrow_fdw/  
  
```  
CREATE FOREIGN TABLE flogdata (  
    ts        timestamp,  
    sensor_id int,  
    signal1   smallint,  
    signal2   smallint,  
    signal3   smallint,  
    signal4   smallint,  
) SERVER arrow_fdw  
  OPTIONS (file '/path/to/logdata.arrow');  
  
  
IMPORT FOREIGN SCHEMA flogdata  
  FROM SERVER arrow_fdw  
  INTO public  
OPTIONS (file '/path/to/logdata.arrow');  
  
  
=# EXPLAIN VERBOSE  
    SELECT sum(lo_extendedprice*lo_discount) as revenue  
      FROM flineorder,date1  
     WHERE lo_orderdate = d_datekey  
       AND d_year = 1993  
       AND lo_discount between 1 and 3  
       AND lo_quantity < 25;  
                              QUERY PLAN  
--------------------------------------------------------------------------------  
 Aggregate  (cost=12632759.02..12632759.03 rows=1 width=32)  
   Output: sum((pgstrom.psum((flineorder.lo_extendedprice * flineorder.lo_discount))))  
   ->  Custom Scan (GpuPreAgg)  (cost=12632754.43..12632757.49 rows=204 width=8)  
         Output: (pgstrom.psum((flineorder.lo_extendedprice * flineorder.lo_discount)))  
         Reduction: NoGroup  
         GPU Projection: flineorder.lo_extendedprice, flineorder.lo_discount, pgstrom.psum((flineorder.lo_extendedprice * flineorder.lo_discount))  
         Combined GpuJoin: enabled  
         GPU Preference: GPU0 (Tesla V100-PCIE-16GB)  
         ->  Custom Scan (GpuJoin) on public.flineorder  (cost=9952.15..12638126.98 rows=572635 width=12)  
               Output: flineorder.lo_extendedprice, flineorder.lo_discount  
               GPU Projection: flineorder.lo_extendedprice::bigint, flineorder.lo_discount::integer  
               Outer Scan: public.flineorder  (cost=9877.70..12649677.69 rows=4010017 width=16)  
               Outer Scan Filter: ((flineorder.lo_discount >= 1) AND (flineorder.lo_discount <= 3) AND (flineorder.lo_quantity < 25))  
               Depth 1: GpuHashJoin  (nrows 4010017...572635)  
                        HashKeys: flineorder.lo_orderdate  
                        JoinQuals: (flineorder.lo_orderdate = date1.d_datekey)  
                        KDS-Hash (size: 66.06KB)  
               GPU Preference: GPU0 (Tesla V100-PCIE-16GB)  
               NVMe-Strom: enabled  
               referenced: lo_orderdate, lo_quantity, lo_extendedprice, lo_discount  
               files0: /opt/nvme/lineorder_s401.arrow (size: 309.23GB)  
                 lo_orderpriority: 33.61GB  
                 lo_extendedprice: 17.93GB  
                 lo_ordertotalprice: 17.93GB  
                 lo_revenue: 17.93GB  
               ->  Seq Scan on public.date1  (cost=0.00..78.95 rows=365 width=4)  
                     Output: date1.d_datekey  
                     Filter: (date1.d_year = 1993)  
(28 rows)  
```  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 云原生分布式开源数据库](https://github.com/ApsaraDB "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、内核开发公开课、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
