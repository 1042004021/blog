## 每天5分钟,PG聊通透 - 系列1 - 热门问题  
                            
### 作者                            
digoal                            
                            
### 日期                            
2021-12-09                          
                            
### 标签                         
PostgreSQL , 热门问题         
                          
----                          
                          
## 背景       
- 问题说明(现象、环境)
- 分析原因
- 结论和解决办法
    
## 链接、驱动、SQL     
    
#### 1、为什么数据库链接长时间空闲时有时侯会自动断开? (长时间空闲, 等待长运行任务)     
https://www.bilibili.com/video/BV1k341147eo/    
```
链路层是否有设备设置了无数据包传输超时断开会话.  确实没有发包、或者在等待长SQL的执行结果返回.  找到设备配置更大的超时, 或者配置数据库keepalive tcp心跳包的频率.
其他:
#statement_timeout = 0                  # in milliseconds, 0 is disabled
#lock_timeout = 0                       # in milliseconds, 0 is disabled
#idle_in_transaction_session_timeout = 0        # in milliseconds, 0 is disabled
#idle_session_timeout = 120000          # in milliseconds, 0 is disabled
```
思考题: 哪些情况可能导致数据库链接被自动断开?    
    
#### 2、为什么会有莫名其妙的连接错误日志?  (心跳探测, 未正确使用PG协议)     
https://www.bilibili.com/video/BV1NM4y1A7bz/  
```
telnet ip port
08P01,"invalid length of startup packet",,,,,,,,,"","not initialized"
未遵循协议, 类似鸡同鸭讲. 人类之间能交流也是奠定在统一的语言体系里面的群体才能正常交流, 未来元宇宙内的数字生命或者软件之间要交互, 提高交互效率, 也需要规范交互协议标准, 包括隐私、安全等.  

log_error_verbosity = verbose
08P01,"invalid length of startup packet",,,,,,,,"ProcessStartupPacket, postmaster.c:1993","","not initialized"

src/backend/postmaster/postmaster.c
```
[《学习 PostgreSQL Frontend/Backend protocol (通信协议)》](../201801/20180122_01.md)  
也可以使用pg_isready来探测, 这个是PG官方的探测客户端, 遵循PG交互协议更加友好.    
    
#### 3、为什么会有大量的idle in transaction|idle事务? 有什么危害?   (事务abort未处理, 框架自动开启事务. 危害之一: 观察事务开启时间以及是否保有backend xmin xid)    
https://www.bilibili.com/video/BV1644y1E7CL/   
```
begin;  
begin; select 1;
begin; insert into x values (xxx);
begin isolation level repeatable read; select 1;

postgres=# select * from pg_stat_activity where state ~ 'idle';
-[ RECORD 1 ]----+--------------------------------
datid            | 13236
datname          | postgres
pid              | 6283
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:18:10.51215+08
xact_start       | 2021-12-11 11:18:11.821312+08
query_start      | 2021-12-11 11:18:13.079184+08
state_change     | 2021-12-11 11:18:13.079559+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction
backend_xid      | 
backend_xmin     | 
query_id         | 
query            | select 1;
backend_type     | client backend
-[ RECORD 2 ]----+--------------------------------
datid            | 13236
datname          | postgres
pid              | 6269
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:17:35.315226+08
xact_start       | 2021-12-11 11:17:47.699981+08
query_start      | 2021-12-11 11:17:49.76987+08
state_change     | 2021-12-11 11:17:49.77028+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction
backend_xid      | 
backend_xmin     | 29753153
query_id         | 
query            | select 1;
backend_type     | client backend
-[ RECORD 3 ]----+--------------------------------
datid            | 13236
datname          | postgres
pid              | 6260
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:17:02.027604+08
xact_start       | 2021-12-11 11:17:09.68111+08
query_start      | 2021-12-11 11:17:15.363823+08
state_change     | 2021-12-11 11:17:15.374042+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction
backend_xid      | 29753153
backend_xmin     | 
query_id         | 
query            | insert into t_age values (1,1);
backend_type     | client backend
-[ RECORD 4 ]----+--------------------------------
datid            | 13236
datname          | postgres
pid              | 6250
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:15:53.414038+08
xact_start       | 2021-12-11 11:15:55.50149+08
query_start      | 2021-12-11 11:15:55.50149+08
state_change     | 2021-12-11 11:15:55.506008+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction
backend_xid      | 
backend_xmin     | 
query_id         | 
query            | begin;
backend_type     | client backend
```
  
```
在backend_xid或backend_xmin有值的事务中, 输入一条错误sql导致事务abort;
abort事务会自动释放snapshot.

-[ RECORD 2 ]----+------------------------------
datid            | 13236
datname          | postgres
pid              | 6269
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:17:35.315226+08
xact_start       | 
query_start      | 2021-12-11 11:20:24.013488+08
state_change     | 2021-12-11 11:20:24.013661+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction (aborted)
backend_xid      | 
backend_xmin     | 
query_id         | 
query            | s;
backend_type     | client backend
```
有backend_xid,backend_xmin的会话(除了vacuum), 不管它处于什么状态, 超出这个value之后新启动的事务所产生的垃圾tuple都不能被vacuum回收. 将会有什么影响呢?    
- 如果系统中还有大量的update,delete操作, 时间久了就可能导致表、索引膨胀, 影响性能、浪费空间.   
- 如果时间非常非常久, 还可能导致事务回卷警告, 甚至需要停库进入数据库单用户模式执行freeze处理后才能使用.      
- 解决方案:   
    - 业务层处理, 避免框架自动开启事务
    - 数据库参数设置, idle_in_transaction_session_timeout  自动释放长时间空闲的事务
    - 设置old_snapshot_threshold数据库参数, 避免vacuum长时间做不下去.  
  
大量idle状态的连接又是怎么回事?   
- 可能DB的性能出现过抖动, 导致业务请求拥塞, 业务端通过新建更多的连接来处理拥塞的请求. 然后业务端又没有配置自动释放空闲连接或者没有到达自动释放空闲连接的超时时间.
- 影响1: 每个会话都有自己的私有内存, 会缓存访问过的对象元数据(例如结构定义), 特别是长连接的影响尤为更大, 因为访问过的对象可能比较多(特别是有分区表时, 每个分区都有独立的元数据), 导致每个会话占用的内存都比较多, 这样的连接多了可能导致系统可自由支配的内存不足, 从而触发OOM. 
- 影响2: 可能占满连接导致别的业务需要连接时报连接不足的错误.  
- 解决方案:   
    - 首先, 是从根上排查和解决拥塞的问题. 
    - 其次, 可以在业务端设置降级保护(例如丢弃请求或者将请求放入队列排队处理, 控制到DB端的最大并发, 确保DB不会被打死导致雪崩的全面业务受损).  
    - 也可以设置数据库idle_session_timeout参数, 让数据库来进行自动释放长时间空闲的会话.  
    - 最后, 在业务端可以调低最大连接数, 同样也是防止过多连接把DB打死.     
    
#### 4、为什么增加连接不能无限提高TPS或QPS? 配置多少个链接合适?     
https://www.bilibili.com/video/BV1Lg411w7z4/   
有时候, 我们可能会遇到这样的情况, 增加链接能提高数据库的TPS或QPS. 所以会带给我们一个假象, 好像要提高tps或qps, 只要增加连接就可以了, 真的是这样吗?             
   
数据库请求过程大致可以简化为:     
- 业务通过网络连接数据库,    
- 提交SQL请求,    
- 数据库处理SQL请求并返回结果.        
    - 从存储获取数据   
    - 存入shared buffer   
    - 非索引可能要逐条计算operator判断tuple是否where条件   
    - 有索引则分是bitmap还是index扫描, 或者分是不是losse索引, 要不要recheck.    
- 期间可能还会有等待, 例如锁等待.      
   
抛开等待的话, SQL请求耗费了哪些资源呢?      
- 网络处理能力: 包转发能力pps、带宽(吞吐)、网络传输延迟RT.     
- 数据库处理SQL请求可能用到:   (都存在单次请求的  响应延迟,  整体请求处理吞吐 上限.)     
    - cpu(计算),     
    - 内存访问,     
    - 内存拷贝,     
    - 存储访问等.      
   
提醒一下: 很多人可能会忽略 响应延迟(RT)、或者其他等待的间隙, 一个请求下去, 到等待请求返回, 这之间都有等待间隙.     
其实我们的世界弥漫着响应延迟(RT), 如小到量子力学, 量子的跳变就是不连续的.  存在间隙.  世界并不是连续的.      
https://www.jianshu.com/p/2ebb10f62a35     
只有假设能量在传播的过程中，不是连续不断的，不存在无限小的单位，而是必须被分成一段、一段的，能量传播必须有一个最小单位，这个完美的公式及黑洞辐射的问题只有使用这种假设才能被解释的通，可一旦这个假设成立，那么便意味着由伽利略、牛顿所建立的经典力学的根基就要被动摇，因为在经典力学中，时间、空间、能量都是连续不断的，可以无限被分割的，普朗克的这个假设就意味着经典力学的根本就是错误的。   
   
什么情况增加连接能提高qps、tps吞吐呢?      
- 当网络、cpu、存储、内存等资源都没有达到其对应的上限时, 加连接可能提高tps、qps.       
- 例如   
    - 1个请求RT是1毫秒. 那么1个链接每秒最多可以处理1000个请求.      
- 如果网络吞吐、CPU资源、内存带宽、存储带宽都没有达到瓶颈.   理论上增加连接还能提高每秒的处理请求数.      
   
那么配置多少个链接合适呢?     
- 可以配置到: 资源耗尽的临界点 ~ 直到出现较大的性能下降(过了临界点后, 再继续增加连接, 性能会出现下降).     
   
例如:    
- 100和1000个链接都能把资源耗光, 那100个肯定比1000个好, 因为:    
    - 每个连接本身还会占用资源, 而且CPU核数有限, 切换cpu时间片也会带来额外的调度性能损耗.    
- 100的整体处理能力通常比1000高.  这也是为什么我们做性能压测会发现连接数达到一定的时候, 性能不升反降.       
   
但是也不是说就一定要配置100个, 因为有些时候这100个可能全是LONG SQL, 遇到短平快的SQL可能没有可用连接, 这个时候怎么办?   
- 建议不同业务可用通过不同的用户或DB进行隔离, 不同的DB、用户配置不同的连接上限.      
    - 类似银行的VIP柜台, 普通柜台.  当普通用户柜台满了还有普通用户来银行办理业务时, VIP柜台就算空着也不给普通用户使用.      
    - 又或者是数据库内核能支持: 当VIP来了, 优先给他分配CPU资源, 让普通SQL处理进入等待.     
   
配置多少个链接合适呢?  经验值:    
1、对于OLTP系统, 如果网络是内网(没有跨网段), 网络RT比较低时.  使用pgbench压测TPC-B, 读性能峰值通常出现在2到4倍CPU核心数. 写性能峰值可能出现在1到2倍CPU核心数.      
2、真实场景, 业务可能并不是不断的发起请求, 而且可能出现占着茅坑不拉屎的情况, 例如业务启动1个事务后, 发起1条SQL, 然后它要等业务自己的逻辑处理, 等个几分钟再发起下一波请求, 最后结束事务.     
这样的情况, 就真的有可能加连接就能提高处理吞吐, 因为你可以理解为一个连接大量的时间处在空闲状态.  这样的情况连接要加到一定数量才能达到数据库的TPS QPS处理峰值.      
   
最后: 要辩证的看待问题, 不能死板.      
   
    
#### 5、为什么无法连接数据库? (监听, pg_hba.conf, role login)      
https://www.bilibili.com/video/BV1bM4y1A7fr/   
- 客户端到数据库之间的网络是否通畅.   
- 防火墙设备是否允许客户端到数据库端端连接.    
- 数据库是否配置了对应网络的监听. 例如 `listen_addresses = '0.0.0.0'`    
- 客户端采用的数据库认证方法是否与pg_hba.conf配置的认证方法一致.   
- pg_hba.conf是从上至下匹配的规则, 匹配到规则后, 下面的规则就不会再看了. 所以如果有多条规则都能命中的话, 优先看第一条.   
- pg_hba.conf是否配置了拒绝客户端登陆.   
- pg_hba.conf是否配置了允许客户端(ip,user,db)登陆.   
- 用户是否有login权限.   
- 是否有login hook不允许登陆.   
    
#### 6、为什么不需要提供密码就能连接数据库?     
https://www.bilibili.com/video/BV16P4y1n7rH  
```
1、
https://www.postgresql.org/docs/14/libpq-pgpass.html
.pgpass
hostname:port:database:username:password
400 .pgpass

2、
https://www.postgresql.org/docs/14/libpq-envars.html
PGPASSWORD
PGPASSFILE

3、
pg_hba.conf
trust
# local         DATABASE  USER  METHOD  [OPTIONS]
# host          DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostssl       DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostnossl     DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostgssenc    DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostnogssenc  DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# TYPE  DATABASE        USER            ADDRESS                 METHOD

# "local" is for Unix domain socket connections only
local   all             all                                     trust
# IPv4 local connections:
host    all             all             127.0.0.1/32            trust
# IPv6 local connections:
host    all             all             ::1/128                 trust
# Allow replication connections from localhost, by a user with the
# replication privilege.
local   replication     all                                     trust
host    replication     all             127.0.0.1/32            trust
host    replication     all             ::1/128                 trust

有些时候在使用或配置dblink, fdw, standby, 备份, 实时接收wal等环境不想配置输入密码时, 都可以使用以上任意方法.  

或者某些映射了OS用户的无密码认证方法配置
```
    
#### 7、为什么有的SQL使用pg_cancel_backend, pg_terminate_backend都杀不掉? (不处理中断信号阶段(HOLD..RESUME中间), src/include/miscadmin.h)    
```
src/include/miscadmin.h

/*****************************************************************************
 *        System interrupt and critical section handling
 *
 * There are two types of interrupts that a running backend needs to accept
 * without messing up its state: QueryCancel (SIGINT) and ProcDie (SIGTERM).
 * In both cases, we need to be able to clean up the current transaction
 * gracefully, so we can't respond to the interrupt instantaneously ---
 * there's no guarantee that internal data structures would be self-consistent
 * if the code is interrupted at an arbitrary instant.  Instead, the signal
 * handlers set flags that are checked periodically during execution.
 *
 * The CHECK_FOR_INTERRUPTS() macro is called at strategically located spots
 * where it is normally safe to accept a cancel or die interrupt.  In some
 * cases, we invoke CHECK_FOR_INTERRUPTS() inside low-level subroutines that
 * might sometimes be called in contexts that do *not* want to allow a cancel
 * or die interrupt.  The HOLD_INTERRUPTS() and RESUME_INTERRUPTS() macros
 * allow code to ensure that no cancel or die interrupt will be accepted,
 * even if CHECK_FOR_INTERRUPTS() gets called in a subroutine.  The interrupt
 * will be held off until CHECK_FOR_INTERRUPTS() is done outside any
 * HOLD_INTERRUPTS() ... RESUME_INTERRUPTS() section.
 *
 * There is also a mechanism to prevent query cancel interrupts, while still
 * allowing die interrupts: HOLD_CANCEL_INTERRUPTS() and
 * RESUME_CANCEL_INTERRUPTS().
 *
 * Note that ProcessInterrupts() has also acquired a number of tasks that
 * do not necessarily cause a query-cancel-or-die response.  Hence, it's
 * possible that it will just clear InterruptPending and return.
 *
 * INTERRUPTS_PENDING_CONDITION() can be checked to see whether an
 * interrupt needs to be serviced, without trying to do so immediately.
 * Some callers are also interested in INTERRUPTS_CAN_BE_PROCESSED(),
 * which tells whether ProcessInterrupts is sure to clear the interrupt.
 *
 * Special mechanisms are used to let an interrupt be accepted when we are
 * waiting for a lock or when we are waiting for command input (but, of
 * course, only if the interrupt holdoff counter is zero).  See the
 * related code for details.
 *
 * A lost connection is handled similarly, although the loss of connection
 * does not raise a signal, but is detected when we fail to write to the
 * socket. If there was a signal for a broken connection, we could make use of
 * it by setting ClientConnectionLost in the signal handler.
 *
 * A related, but conceptually distinct, mechanism is the "critical section"
 * mechanism.  A critical section not only holds off cancel/die interrupts,
 * but causes any ereport(ERROR) or ereport(FATAL) to become ereport(PANIC)
 * --- that is, a system-wide reset is forced.  Needless to say, only really
 * *critical* code should be marked as a critical section!      Currently, this
 * mechanism is only used for XLOG-related code.
 *
 *****************************************************************************/


src/backend/tcop/postgres.c

/*
 * ProcessInterrupts: out-of-line portion of CHECK_FOR_INTERRUPTS() macro
 *
 * If an interrupt condition is pending, and it's safe to service it,
 * then clear the flag and accept the interrupt.  Called only when
 * InterruptPending is true.
 *
 * Note: if INTERRUPTS_CAN_BE_PROCESSED() is true, then ProcessInterrupts
 * is guaranteed to clear the InterruptPending flag before returning.
 * (This is not the same as guaranteeing that it's still clear when we
 * return; another interrupt could have arrived.  But we promise that
 * any pre-existing one will have been serviced.)
 */
void
ProcessInterrupts(void)
{

....
```
    
#### 8、为什么order by并没有按中文拼音排序? (LC collate)     
字符串排序受什么影响?   
- LC_COLLATE (string sort order)   
   
几处可以指定collate:     
- 初始化PostgreSQL 实例时指定template的collate   
- 创建数据库时指定数据库的默认collate   
- 指定表字段的collate   
- 排序时指定collate   
- 创建索引时指定collate   
    - 用到这样的索引必须在order by排序时使用与索引一样的collate, 否则索引不会被使用     
   
中文拼音排序推荐用法:     
- `order by convert_to(字符串字段,'EUC_CN');`  简体   
- `order by convert_to(info,'GB18030');`  简体+繁体+少数民族字体+各种中国的符号   
   
```   
postgres=# select * from (values ('刘德华'),('刘少奇'),('张学友'),('郭富城'),('郭德纲'),('黎明'),('李刚'),('中山'),('重庆'),('冲哥')) as t(info)    
order by info collate "C";   
  info     
--------   
 中山   
 冲哥   
 刘少奇   
 刘德华   
 张学友   
 李刚   
 郭富城   
 郭德纲   
 重庆   
 黎明   
(10 rows)   
   
postgres=# select * from (values ('刘德华'),('刘少奇'),('张学友'),('郭富城'),('郭德纲'),('黎明'),('李刚'),('中山'),('重庆'),('冲哥')) as t(info)    
order by info collate "zh_CN";   
  info     
--------   
 中山   
 冲哥   
 李刚   
 重庆   
 黎明   
 刘少奇   
 刘德华   
 张学友   
 郭富城   
 郭德纲   
(10 rows)   
   
   
postgres=# select * from (values ('刘德华'),('刘少奇'),('张学友'),('郭富城'),('郭德纲'),('黎明'),('李刚'),('中山'),('重庆'),('冲哥')) as t(info)    
order by convert_to(info,'GB18030');   
  info     
--------   
 冲哥   
 郭德纲   
 郭富城   
 黎明   
 李刚   
 刘德华   
 刘少奇   
 张学友   
 中山   
 重庆   
(10 rows)   
   
postgres=# select * from (values ('刘德华'),('刘少奇'),('张学友'),('郭富城'),('郭德纲'),('黎明'),('李刚'),('中山'),('重庆'),('冲哥')) as t(info)    
order by convert_to(info,'EUC_CN');   
  info     
--------   
 冲哥   
 郭德纲   
 郭富城   
 黎明   
 李刚   
 刘德华   
 刘少奇   
 张学友   
 中山   
 重庆   
(10 rows)   
   
postgres=# \df convert_to   
                            List of functions   
   Schema   |    Name    | Result data type | Argument data types | Type    
------------+------------+------------------+---------------------+------   
 pg_catalog | convert_to | bytea            | text, name          | func   
(1 row)   
```   
   
参考:   
- PostgreSQL 支持的服务端与客户端字符集:     
    - https://www.postgresql.org/docs/current/multibyte.html   
- [《PostgreSQL MySQL 兼容性之 - order by 拼音 or binary or 指定 collate》](../202010/20201031_04.md)     
- [《如何按拼音排序 - 数据库本土化特性(collate, ctype, ...)》](../201704/20170424_03.md)     
- [《PostgreSQL 按拼音排序 - convert to GBK/EUC_CN coding》](../201612/20161205_01.md)     
- 中文相关字符集   
    - GB2312（简体），   
    - GBK（简体+繁体），   
    - GB18030（简体+繁体+少数民族字体+各种中国的符号）   
    - EUC_CN	Extended UNIX Code-CN	Simplified Chinese   
    - BIG5	Big Five	Traditional Chinese   
    - EUC_TW	Extended UNIX Code-TW	Traditional Chinese, Taiwanese   
          
    
#### 9、为什么OFFSET会越来越慢?     
  
参考:  
- [《PostgreSQL 分页, offset, 返回顺序, 扫描方法原理(seqscan, index scan, index only scan, bitmap scan, parallel xx scan)，游标》](../201902/20190228_01.md)  
- [《PostgreSQL 范围过滤 + 其他字段排序OFFSET LIMIT(多字段区间过滤)的优化与加速》](../201801/20180122_02.md)  
- [《PostgreSQL 索引扫描offset内核优化 - case》](../201607/20160717_01.md)  
- [《PostgreSQL 数据访问 offset 的质变 case》](../201607/20160715_02.md)  
- [《论count与offset使用不当的罪名 和 分页的优化》](../201605/20160506_01.md)  
- [《PostgreSQL offset 原理，及使用注意事项》](../201604/20160402_02.md)  
- [《分页优化 - order by limit x offset y performance tuning》](../201402/20140211_01.md)  
  
    
10、为什么有的索引不支持字符串前置查询? (patten, lc_collate)       
    
11、为什么count查询慢?       
    
12、为什么SQL会自动启用并行计算?     
    
13、为什么长时间等待业务处理的情况不建议封装在事务中?       
    
14、为什么会有死锁?       
    
15、为什么业务开启多会话并行后反而慢?    (死锁, 等待, 业务逻辑处理有问题)      
    
16、为什么说有些排序操作建议让业务来做?     
    
17、为什么说有些逻辑应该交给数据库存储过程来做?   (短平快高频多次交互)    
    
18、为什么性能差? 如何找到捣蛋鬼SQL?    (top sql)      
    
19、为什么SQL性能会抖动?    (P99 , 资源争抢, 锁等待, 执行计划抖动...)      
    
20、为什么分区表的分区过多会导致性能下降?      
    
21、为什么要用绑定变量?   (安全、短平快)       
    
22、为什么创建索引会堵塞DML?  如何在线创建索引?      
    
23、为什么有的函数不能被用来创建表达式索引?     (stable, volatile)        
    
24、为什么与检索字段类型不一致的输入条件有时可能不能采用索引?        
    
    
## 备份、订阅、恢复    
    
1、为什么逻辑复制在主从切换后会丢数据?         
    
2、为什么有备份但是不能恢复到指定时间点?   (时区指定有问题、目标时间早于全量备份到逻辑一致位点)       
    
3、为什么逻辑备份可能和业务产生冲突?       
    
4、为什么逻辑备份可能导致实例膨胀?       
    
    
## 从库    
    
1、为什么在从库上跑长事务或长SQL可能会报错?      
    
2、为什么从库会出现回放延迟?      
    
3、为什么主备切换后并不总是需要重建HA或重建灾难备份库?      
    
4、为什么有时从库会报上游WAL日志已删除的错误?      
    
    
## 性能、管理    
    
1、为什么默认配置性能比较差?      
    
2、为什么要关闭NUMA?       
    
3、为什么高并发的短链接性能会很差?      
    
4、为什么会发生OOM?         (adj 防止 https://github.com/digoal/blog/blob/master/201801/20180121_01.md)      
    
5、为什么存在内存浪费严重的现象?   (relcache, 分区表, 内存霸占, 未开启huge page页表浪费)      
    
6、为什么在操作系统直接kill 数据库进程会导致数据库重启?      
    
7、为什么会出现数据库块损坏?      
    
8、为什么存在与业务无关的突发IO和CPU飙升?     
    
9、为什么存在与业务无关的持续IO与CPU消耗?     
    
10、为什么表会膨胀?            (https://github.com/digoal/blog/blob/master/201801/20180121_01.md)    
    
11、为什么索引会膨胀?         
    
12、为什么垃圾回收有时不起作用?       
    
13、为什么log日志量暴增而且影响性能?  (审计, pipeline buffer, 使用采样日志)       
    
14、为什么WAL日志会堆积?       (https://github.com/digoal/blog/blob/master/201801/20180121_01.md)    
    
15、为什么WAL会突然暴增?      
    
16、为什么数据文件会突然暴增?      (递归死循环、某些大的查询可能导致临时文件的大量产生  https://github.com/digoal/blog/blob/master/201801/20180121_01.md)    
    
17、为什么会出现雪崩?      
    
18、为什么大量delete后表和索引的空间没有变小?   (高水位)      
    
19、如何在线降低表、索引水位?      
    
20、为什么push|pull大量数据的读写比较慢?     (COPY, pipeline模式)      
    
21、怎么判断数据库有没有瓶颈?  (处理能力有没有到顶? 还能支撑多大的业务增长?)       
    
22、如何发现过去、现在、未来的性能问题?      
    
23、为什么SQL执行计划不正确?     
    
## 业务    
1、为什么时序类搜索可能有IO放大，除了 cpu,io,net 还有哪些隐藏的瓶颈，为什么要聚集?    
    
2、为什么空间搜索有IO放大，为什么要数据聚集， 为什么要分裂查询?     
    
3、为什么有时索引扫描并不比全表扫描更快?      
    
4、为什么GIN有时不快?        
    
5、为什么BRIN有时不快?        
  
6、为什么输入顺序会影响最终GiST创建出来的索引性能?  
    
7、有几种索引、该如何选择索引?        
    
## 安全    
1、为什么会有SQL注入?       
    
2、为什么赋予了select权限依旧无权查询表? (逻辑结构)     
- 怎么赋予默认只读权限    
- 怎么赋予默认写权限    
- 怎么赋予新增表的默认权限    
- 怎么赋予已有表的默认权限    
    
3、为什么事务号会耗尽?      
    
4、为什么慢SQL，空闲事务，长事务，2PC，慢SLOT，standby feedback，强制vacuum age defer都存在风险    
    
    
  
#### [期望 PostgreSQL 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [类似Oracle RAC架构的PostgreSQL已开源: 阿里云PolarDB for PostgreSQL云原生分布式开源数据库!](https://github.com/ApsaraDB/PolarDB-for-PostgreSQL "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
