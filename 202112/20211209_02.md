## 每天5分钟,PG聊通透 - 系列1 - 热门问题  
                            
### 作者                            
digoal                            
                            
### 日期                            
2021-12-09                          
                            
### 标签                         
PostgreSQL , 热门问题         
                          
----                          
                          
## 背景       
- 问题说明(现象、环境)
- 分析原因
- 结论和解决办法
    
## 链接、驱动、SQL     
    
#### 1、为什么数据库链接长时间空闲时有时侯会自动断开? (长时间空闲, 等待长运行任务)     
https://www.bilibili.com/video/BV1k341147eo/    
```
链路层是否有设备设置了无数据包传输超时断开会话.  确实没有发包、或者在等待长SQL的执行结果返回.  找到设备配置更大的超时, 或者配置数据库keepalive tcp心跳包的频率.
其他:
#statement_timeout = 0                  # in milliseconds, 0 is disabled
#lock_timeout = 0                       # in milliseconds, 0 is disabled
#idle_in_transaction_session_timeout = 0        # in milliseconds, 0 is disabled
#idle_session_timeout = 120000          # in milliseconds, 0 is disabled
```
思考题: 哪些情况可能导致数据库链接被自动断开?    
    
#### 2、为什么会有莫名其妙的连接错误日志?  (心跳探测, 未正确使用PG协议)     
https://www.bilibili.com/video/BV1NM4y1A7bz/  
```
telnet ip port
08P01,"invalid length of startup packet",,,,,,,,,"","not initialized"
未遵循协议, 类似鸡同鸭讲. 人类之间能交流也是奠定在统一的语言体系里面的群体才能正常交流, 未来元宇宙内的数字生命或者软件之间要交互, 提高交互效率, 也需要规范交互协议标准, 包括隐私、安全等.  

log_error_verbosity = verbose
08P01,"invalid length of startup packet",,,,,,,,"ProcessStartupPacket, postmaster.c:1993","","not initialized"

src/backend/postmaster/postmaster.c
```
[《学习 PostgreSQL Frontend/Backend protocol (通信协议)》](../201801/20180122_01.md)  
也可以使用pg_isready来探测, 这个是PG官方的探测客户端, 遵循PG交互协议更加友好.    
    
#### 3、为什么会有大量的idle in transaction|idle事务? 有什么危害?   (事务abort未处理, 框架自动开启事务. 危害之一: 观察事务开启时间以及是否保有backend xmin xid)    
https://www.bilibili.com/video/BV1644y1E7CL/   
```
begin;  
begin; select 1;
begin; insert into x values (xxx);
begin isolation level repeatable read; select 1;

postgres=# select * from pg_stat_activity where state ~ 'idle';
-[ RECORD 1 ]----+--------------------------------
datid            | 13236
datname          | postgres
pid              | 6283
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:18:10.51215+08
xact_start       | 2021-12-11 11:18:11.821312+08
query_start      | 2021-12-11 11:18:13.079184+08
state_change     | 2021-12-11 11:18:13.079559+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction
backend_xid      | 
backend_xmin     | 
query_id         | 
query            | select 1;
backend_type     | client backend
-[ RECORD 2 ]----+--------------------------------
datid            | 13236
datname          | postgres
pid              | 6269
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:17:35.315226+08
xact_start       | 2021-12-11 11:17:47.699981+08
query_start      | 2021-12-11 11:17:49.76987+08
state_change     | 2021-12-11 11:17:49.77028+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction
backend_xid      | 
backend_xmin     | 29753153
query_id         | 
query            | select 1;
backend_type     | client backend
-[ RECORD 3 ]----+--------------------------------
datid            | 13236
datname          | postgres
pid              | 6260
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:17:02.027604+08
xact_start       | 2021-12-11 11:17:09.68111+08
query_start      | 2021-12-11 11:17:15.363823+08
state_change     | 2021-12-11 11:17:15.374042+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction
backend_xid      | 29753153
backend_xmin     | 
query_id         | 
query            | insert into t_age values (1,1);
backend_type     | client backend
-[ RECORD 4 ]----+--------------------------------
datid            | 13236
datname          | postgres
pid              | 6250
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:15:53.414038+08
xact_start       | 2021-12-11 11:15:55.50149+08
query_start      | 2021-12-11 11:15:55.50149+08
state_change     | 2021-12-11 11:15:55.506008+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction
backend_xid      | 
backend_xmin     | 
query_id         | 
query            | begin;
backend_type     | client backend
```
  
```
在backend_xid或backend_xmin有值的事务中, 输入一条错误sql导致事务abort;
abort事务会自动释放snapshot.

-[ RECORD 2 ]----+------------------------------
datid            | 13236
datname          | postgres
pid              | 6269
leader_pid       | 
usesysid         | 10
usename          | postgres
application_name | psql
client_addr      | 
client_hostname  | 
client_port      | -1
backend_start    | 2021-12-11 11:17:35.315226+08
xact_start       | 
query_start      | 2021-12-11 11:20:24.013488+08
state_change     | 2021-12-11 11:20:24.013661+08
wait_event_type  | Client
wait_event       | ClientRead
state            | idle in transaction (aborted)
backend_xid      | 
backend_xmin     | 
query_id         | 
query            | s;
backend_type     | client backend
```
有backend_xid,backend_xmin的会话(除了vacuum), 不管它处于什么状态, 超出这个value之后新启动的事务所产生的垃圾tuple都不能被vacuum回收. 将会有什么影响呢?    
- 如果系统中还有大量的update,delete操作, 时间久了就可能导致表、索引膨胀, 影响性能、浪费空间.   
- 如果时间非常非常久, 还可能导致事务回卷警告, 甚至需要停库进入数据库单用户模式执行freeze处理后才能使用.      
- 解决方案:   
    - 业务层处理, 避免框架自动开启事务
    - 数据库参数设置, idle_in_transaction_session_timeout  自动释放长时间空闲的事务
    - 设置old_snapshot_threshold数据库参数, 避免vacuum长时间做不下去.  
  
大量idle状态的连接又是怎么回事?   
- 可能DB的性能出现过抖动, 导致业务请求拥塞, 业务端通过新建更多的连接来处理拥塞的请求. 然后业务端又没有配置自动释放空闲连接或者没有到达自动释放空闲连接的超时时间.
- 影响1: 每个会话都有自己的私有内存, 会缓存访问过的对象元数据(例如结构定义), 特别是长连接的影响尤为更大, 因为访问过的对象可能比较多(特别是有分区表时, 每个分区都有独立的元数据), 导致每个会话占用的内存都比较多, 这样的连接多了可能导致系统可自由支配的内存不足, 从而触发OOM. 
- 影响2: 可能占满连接导致别的业务需要连接时报连接不足的错误.  
- 解决方案:   
    - 首先, 是从根上排查和解决拥塞的问题. 
    - 其次, 可以在业务端设置降级保护(例如丢弃请求或者将请求放入队列排队处理, 控制到DB端的最大并发, 确保DB不会被打死导致雪崩的全面业务受损).  
    - 也可以设置数据库idle_session_timeout参数, 让数据库来进行自动释放长时间空闲的会话.  
    - 最后, 在业务端可以调低最大连接数, 同样也是防止过多连接把DB打死.     
    
#### 4、为什么增加连接不能无限提高TPS或QPS? 配置多少个链接合适?     
https://www.bilibili.com/video/BV1Lg411w7z4/   
有时候, 我们可能会遇到这样的情况, 增加链接能提高数据库的TPS或QPS. 所以会带给我们一个假象, 好像要提高tps或qps, 只要增加连接就可以了, 真的是这样吗?             
   
数据库请求过程大致可以简化为:     
- 业务通过网络连接数据库,    
- 提交SQL请求,    
- 数据库处理SQL请求并返回结果.        
    - 从存储获取数据   
    - 存入shared buffer   
    - 非索引可能要逐条计算operator判断tuple是否where条件   
    - 有索引则分是bitmap还是index扫描, 或者分是不是losse索引, 要不要recheck.    
- 期间可能还会有等待, 例如锁等待.      
   
抛开等待的话, SQL请求耗费了哪些资源呢?      
- 网络处理能力: 包转发能力pps、带宽(吞吐)、网络传输延迟RT.     
- 数据库处理SQL请求可能用到:   (都存在单次请求的  响应延迟,  整体请求处理吞吐 上限.)     
    - cpu(计算),     
    - 内存访问,     
    - 内存拷贝,     
    - 存储访问等.      
   
提醒一下: 很多人可能会忽略 响应延迟(RT)、或者其他等待的间隙, 一个请求下去, 到等待请求返回, 这之间都有等待间隙.     
其实我们的世界弥漫着响应延迟(RT), 如小到量子力学, 量子的跳变就是不连续的.  存在间隙.  世界并不是连续的.      
https://www.jianshu.com/p/2ebb10f62a35     
只有假设能量在传播的过程中，不是连续不断的，不存在无限小的单位，而是必须被分成一段、一段的，能量传播必须有一个最小单位，这个完美的公式及黑洞辐射的问题只有使用这种假设才能被解释的通，可一旦这个假设成立，那么便意味着由伽利略、牛顿所建立的经典力学的根基就要被动摇，因为在经典力学中，时间、空间、能量都是连续不断的，可以无限被分割的，普朗克的这个假设就意味着经典力学的根本就是错误的。   
   
什么情况增加连接能提高qps、tps吞吐呢?      
- 当网络、cpu、存储、内存等资源都没有达到其对应的上限时, 加连接可能提高tps、qps.       
- 例如   
    - 1个请求RT是1毫秒. 那么1个链接每秒最多可以处理1000个请求.      
- 如果网络吞吐、CPU资源、内存带宽、存储带宽都没有达到瓶颈.   理论上增加连接还能提高每秒的处理请求数.      
   
那么配置多少个链接合适呢?     
- 可以配置到: 资源耗尽的临界点 ~ 直到出现较大的性能下降(过了临界点后, 再继续增加连接, 性能会出现下降).     
   
例如:    
- 100和1000个链接都能把资源耗光, 那100个肯定比1000个好, 因为:    
    - 每个连接本身还会占用资源, 而且CPU核数有限, 切换cpu时间片也会带来额外的调度性能损耗.    
- 100的整体处理能力通常比1000高.  这也是为什么我们做性能压测会发现连接数达到一定的时候, 性能不升反降.       
   
但是也不是说就一定要配置100个, 因为有些时候这100个可能全是LONG SQL, 遇到短平快的SQL可能没有可用连接, 这个时候怎么办?   
- 建议不同业务可用通过不同的用户或DB进行隔离, 不同的DB、用户配置不同的连接上限.      
    - 类似银行的VIP柜台, 普通柜台.  当普通用户柜台满了还有普通用户来银行办理业务时, VIP柜台就算空着也不给普通用户使用.      
    - 又或者是数据库内核能支持: 当VIP来了, 优先给他分配CPU资源, 让普通SQL处理进入等待.     
   
配置多少个链接合适呢?  经验值:    
1、对于OLTP系统, 如果网络是内网(没有跨网段), 网络RT比较低时.  使用pgbench压测TPC-B, 读性能峰值通常出现在2到4倍CPU核心数. 写性能峰值可能出现在1到2倍CPU核心数.      
2、真实场景, 业务可能并不是不断的发起请求, 而且可能出现占着茅坑不拉屎的情况, 例如业务启动1个事务后, 发起1条SQL, 然后它要等业务自己的逻辑处理, 等个几分钟再发起下一波请求, 最后结束事务.     
这样的情况, 就真的有可能加连接就能提高处理吞吐, 因为你可以理解为一个连接大量的时间处在空闲状态.  这样的情况连接要加到一定数量才能达到数据库的TPS QPS处理峰值.      
   
最后: 要辩证的看待问题, 不能死板.      
   
    
#### 5、为什么无法连接数据库? (监听, pg_hba.conf, role login)      
https://www.bilibili.com/video/BV1bM4y1A7fr/   
- 客户端到数据库之间的网络是否通畅.   
- 防火墙设备是否允许客户端到数据库端端连接.    
- 数据库是否配置了对应网络的监听. 例如 `listen_addresses = '0.0.0.0'`    
- 客户端采用的数据库认证方法是否与pg_hba.conf配置的认证方法一致.   
- pg_hba.conf是从上至下匹配的规则, 匹配到规则后, 下面的规则就不会再看了. 所以如果有多条规则都能命中的话, 优先看第一条.   
- pg_hba.conf是否配置了拒绝客户端登陆.   
- pg_hba.conf是否配置了允许客户端(ip,user,db)登陆.   
- 用户是否有login权限.   
- 是否有login hook不允许登陆.   
    
#### 6、为什么不需要提供密码就能连接数据库?     
https://www.bilibili.com/video/BV16P4y1n7rH  
```
1、
https://www.postgresql.org/docs/14/libpq-pgpass.html
.pgpass
hostname:port:database:username:password
400 .pgpass

2、
https://www.postgresql.org/docs/14/libpq-envars.html
PGPASSWORD
PGPASSFILE

3、
pg_hba.conf
trust
# local         DATABASE  USER  METHOD  [OPTIONS]
# host          DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostssl       DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostnossl     DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostgssenc    DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostnogssenc  DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# TYPE  DATABASE        USER            ADDRESS                 METHOD

# "local" is for Unix domain socket connections only
local   all             all                                     trust
# IPv4 local connections:
host    all             all             127.0.0.1/32            trust
# IPv6 local connections:
host    all             all             ::1/128                 trust
# Allow replication connections from localhost, by a user with the
# replication privilege.
local   replication     all                                     trust
host    replication     all             127.0.0.1/32            trust
host    replication     all             ::1/128                 trust

有些时候在使用或配置dblink, fdw, standby, 备份, 实时接收wal等环境不想配置输入密码时, 都可以使用以上任意方法.  

或者某些映射了OS用户的无密码认证方法配置
```
    
#### 7、为什么有的SQL使用pg_cancel_backend, pg_terminate_backend都杀不掉? (不处理中断信号阶段(HOLD..RESUME中间), src/include/miscadmin.h)    
https://www.bilibili.com/video/BV1EQ4y1Y7kY/   
```
src/include/miscadmin.h

/*****************************************************************************
 *        System interrupt and critical section handling
 *
 * There are two types of interrupts that a running backend needs to accept
 * without messing up its state: QueryCancel (SIGINT) and ProcDie (SIGTERM).
 * In both cases, we need to be able to clean up the current transaction
 * gracefully, so we can't respond to the interrupt instantaneously ---
 * there's no guarantee that internal data structures would be self-consistent
 * if the code is interrupted at an arbitrary instant.  Instead, the signal
 * handlers set flags that are checked periodically during execution.
 *
 * The CHECK_FOR_INTERRUPTS() macro is called at strategically located spots
 * where it is normally safe to accept a cancel or die interrupt.  In some
 * cases, we invoke CHECK_FOR_INTERRUPTS() inside low-level subroutines that
 * might sometimes be called in contexts that do *not* want to allow a cancel
 * or die interrupt.  The HOLD_INTERRUPTS() and RESUME_INTERRUPTS() macros
 * allow code to ensure that no cancel or die interrupt will be accepted,
 * even if CHECK_FOR_INTERRUPTS() gets called in a subroutine.  The interrupt
 * will be held off until CHECK_FOR_INTERRUPTS() is done outside any
 * HOLD_INTERRUPTS() ... RESUME_INTERRUPTS() section.
 *
 * There is also a mechanism to prevent query cancel interrupts, while still
 * allowing die interrupts: HOLD_CANCEL_INTERRUPTS() and
 * RESUME_CANCEL_INTERRUPTS().
 *
 * Note that ProcessInterrupts() has also acquired a number of tasks that
 * do not necessarily cause a query-cancel-or-die response.  Hence, it's
 * possible that it will just clear InterruptPending and return.
 *
 * INTERRUPTS_PENDING_CONDITION() can be checked to see whether an
 * interrupt needs to be serviced, without trying to do so immediately.
 * Some callers are also interested in INTERRUPTS_CAN_BE_PROCESSED(),
 * which tells whether ProcessInterrupts is sure to clear the interrupt.
 *
 * Special mechanisms are used to let an interrupt be accepted when we are
 * waiting for a lock or when we are waiting for command input (but, of
 * course, only if the interrupt holdoff counter is zero).  See the
 * related code for details.
 *
 * A lost connection is handled similarly, although the loss of connection
 * does not raise a signal, but is detected when we fail to write to the
 * socket. If there was a signal for a broken connection, we could make use of
 * it by setting ClientConnectionLost in the signal handler.
 *
 * A related, but conceptually distinct, mechanism is the "critical section"
 * mechanism.  A critical section not only holds off cancel/die interrupts,
 * but causes any ereport(ERROR) or ereport(FATAL) to become ereport(PANIC)
 * --- that is, a system-wide reset is forced.  Needless to say, only really
 * *critical* code should be marked as a critical section!      Currently, this
 * mechanism is only used for XLOG-related code.
 *
 *****************************************************************************/


src/backend/tcop/postgres.c

/*
 * ProcessInterrupts: out-of-line portion of CHECK_FOR_INTERRUPTS() macro
 *
 * If an interrupt condition is pending, and it's safe to service it,
 * then clear the flag and accept the interrupt.  Called only when
 * InterruptPending is true.
 *
 * Note: if INTERRUPTS_CAN_BE_PROCESSED() is true, then ProcessInterrupts
 * is guaranteed to clear the InterruptPending flag before returning.
 * (This is not the same as guaranteeing that it's still clear when we
 * return; another interrupt could have arrived.  But we promise that
 * any pre-existing one will have been serviced.)
 */
void
ProcessInterrupts(void)
{

....
```
下次遇到杀不掉的可以用pstack看看杀不掉的进程在干什么, 找找对应的代码是否能找到是不是调用了hold中断.   
      
#### 8、为什么order by并没有按中文拼音排序? (LC collate)     
https://www.bilibili.com/video/BV1KR4y1W7BU/   
字符串排序受什么影响?   
- 字符集
- LC_COLLATE (string sort order)   
   
几处可以指定collate:     
- 初始化PostgreSQL 实例时指定template的collate   
- 创建数据库时指定数据库的默认collate   
- 指定表字段的collate   
- 排序时指定collate   
- 创建索引时指定collate   
    - 用到这样的索引必须在order by排序时使用与索引一样的collate, 否则索引不会被使用     
   
中文拼音排序推荐用法:     
- `order by convert_to(字符串字段,'EUC_CN');`  简体   
- `order by convert_to(info,'GB18030');`  简体+繁体+少数民族字体+各种中国的符号   
   
```   
postgres=# select * from (values ('刘德华'),('刘少奇'),('张学友'),('郭富城'),('郭德纲'),('黎明'),('李刚'),('中山'),('重庆'),('冲哥')) as t(info)    
order by info collate "C";   
  info     
--------   
 中山   
 冲哥   
 刘少奇   
 刘德华   
 张学友   
 李刚   
 郭富城   
 郭德纲   
 重庆   
 黎明   
(10 rows)   
   
postgres=# select * from (values ('刘德华'),('刘少奇'),('张学友'),('郭富城'),('郭德纲'),('黎明'),('李刚'),('中山'),('重庆'),('冲哥')) as t(info)    
order by info collate "zh_CN";   
  info     
--------   
 中山   
 冲哥   
 李刚   
 重庆   
 黎明   
 刘少奇   
 刘德华   
 张学友   
 郭富城   
 郭德纲   
(10 rows)   
   
   
postgres=# select * from (values ('刘德华'),('刘少奇'),('张学友'),('郭富城'),('郭德纲'),('黎明'),('李刚'),('中山'),('重庆'),('冲哥')) as t(info)    
order by convert_to(info,'GB18030');   
  info     
--------   
 冲哥   
 郭德纲   
 郭富城   
 黎明   
 李刚   
 刘德华   
 刘少奇   
 张学友   
 中山   
 重庆   
(10 rows)   
   
postgres=# select * from (values ('刘德华'),('刘少奇'),('张学友'),('郭富城'),('郭德纲'),('黎明'),('李刚'),('中山'),('重庆'),('冲哥')) as t(info)    
order by convert_to(info,'EUC_CN');   
  info     
--------   
 冲哥   
 郭德纲   
 郭富城   
 黎明   
 李刚   
 刘德华   
 刘少奇   
 张学友   
 中山   
 重庆   
(10 rows)   
   
postgres=# \df convert_to   
                            List of functions   
   Schema   |    Name    | Result data type | Argument data types | Type    
------------+------------+------------------+---------------------+------   
 pg_catalog | convert_to | bytea            | text, name          | func   
(1 row)   
```   
   
```
索引必须是immutable的.

postgres=# create index idx_d_1 on d (convert_to(c1,'GBK'));
ERROR:  functions in index expression must be marked IMMUTABLE
postgres=# create or replace function immut_convert_to(text,text) returns bytea as $$
postgres$#   select convert_to($1,$2);
postgres$# $$ language sql strict immutable;
CREATE FUNCTION
postgres=# create index idx_d_1 on d (immut_convert_to(c1,'GBK'));                                                                                                                                        CREATE INDEX

postgres=# set enable_sort=off;
SET
postgres=# explain select * from d order by immut_convert_to(c1, 'GBK'::text);
                            QUERY PLAN                            
------------------------------------------------------------------
 Index Scan using idx_d_1 on d  (cost=0.12..2.59 rows=1 width=64)
(1 row)
```
   
参考:   
- PostgreSQL 支持的服务端与客户端字符集:     
    - https://www.postgresql.org/docs/current/multibyte.html   
- [《PostgreSQL MySQL 兼容性之 - order by 拼音 or binary or 指定 collate》](../202010/20201031_04.md)     
- [《如何按拼音排序 - 数据库本土化特性(collate, ctype, ...)》](../201704/20170424_03.md)     
- [《PostgreSQL 按拼音排序 - convert to GBK/EUC_CN coding》](../201612/20161205_01.md)     
- 中文相关字符集,注意有的只能作为客户端编码, 有的既能作为客户端编码也能作为服务端编码.     
    - GB2312（简体），   
    - GBK（简体+繁体），   
    - GB18030（简体+繁体+少数民族字体+各种中国的符号）   
    - EUC_CN	Extended UNIX Code-CN	Simplified Chinese   
    - BIG5	Big Five	Traditional Chinese   
    - EUC_TW	Extended UNIX Code-TW	Traditional Chinese, Taiwanese   
          
    
#### 9、为什么OFFSET会越来越慢?     
1、offset 通常用在什么场景使用?   
翻页?    
   
2、数据库怎么知道 offset 了多少条符合条件的记录?   
   
首先扯远一点, 如果是个数组, 元组size固定, 大家思考一下offset怎么做到最快? 可以根据offset的个数算出起点, 将访问起点直接位移到指定存储地址. 例如4字节的元组, offset 100, 直接跳到400字节开始访问即可. 所以这样的访问不管offset多少性能都不会变慢.     
   
但是, 不管是索引扫描, 还是全表扫描, 亦或索引+其他非索引条件过滤, 输入条件都可能是变化的、而且元组的长度、索引的长度也可能是变化的, 更重要的是数据的组织形式并不是向数组一样顺序组织的. 所以没有办法像array一样, 直接位移存储来进行优化, 这也是为啥offset越后面越慢的原因?  下面用2个例子详细解释一下:    
   
`where x=? and y>? order by x limit 10 offset 100`     
- 使用x索引, y条件并不可知, 所以得遍历符合x条件的索引页.     
- 就算y条件也在索引中, 那么请看下面的另一个例子.       
   
`order by x limit 10 offset 100`     
- 使用x索引, 也得从索引遍历100条后, 才能获取后面的. 为什么要遍历这100条呢?     
- 索引没有版本号, 不遍历offset的条数, 怎么知道这条记录对当前事务是否可见.     
- 就算索引有版本号, 它也得读每条上面的版本号才能判断是否这条记录是否对当前事务可见, 所以还得遍历offset的条数.     
- 就算整个page有个全局可见标识, 它怎么知道1个index page里面有多少条记录? 以及一个page的value边界是什么? 所以还得遍历offset的条数.     
- 就算叶子结点知道每个index page有多少条, 但是分支节点和根节点总不知道吧?    
    - 因为任何一个结点, 如果要存储它的所有下游结点有多少条记录, 就必须实时更新.    
    - 对于根节点来说,  任何的插入更新删除都会涉及根节点的更新, 性能影响一定是极大的.    
    - 对于分支节点, 只有它下面的叶子结点中的记录有插入更新删除才会涉及到这个分支节点的更新.    
    - 对于叶子结点来说,  影响只在这个叶子里面的记录的增删改.    
    - 所以通常不会这么设计, 除非是静态数据.     
    - 那么通常只有叶子结点才知道它这个page有多少条记录以及value边界, 所以至少还是得按逻辑顺序扫描叶子结点的头信息(获取这个叶子结点有多少条记录).     
   
说这么多, 就是要证明 offset big value 没法在通用数据库的内核中进行优化(除非你的数据是静态数据, 内核才有优化的必要).    
如果关心索引结构可以看一下:   
- [《PostgreSQL rum 索引结构 - 比gin posting list|tree 的ctid(行号)多了addition info》](../201907/20190706_01.md)  
- [《[未完待续] PostgreSQL hash 索引结构介绍》](../201803/20180316_02.md)  
- [《深入浅出PostgreSQL B-Tree索引结构》](../201605/20160528_01.md)  
- [《PostgreSQL bloom 索引原理》](../202011/20201128_04.md)  
- [《PostgreSQL RUM 索引原理》](../202011/20201128_02.md)  
- [《PostgreSQL SP-GiST 索引原理》](../202011/20201128_01.md)  
- [《PostgreSQL GiST 索引原理 - 4》](../202010/20201004_04.md)  
- [《PostgreSQL GiST 索引原理 - 3》](../202010/20201004_03.md)  
- [《PostgreSQL GiST 索引原理 - 2》](../202010/20201004_02.md)  
- [《PostgreSQL GiST 索引原理 - 1》](../202010/20201004_01.md)  
- [《从难缠的模糊查询聊开 - PostgreSQL独门绝招之一 GIN , GiST , SP-GiST , RUM 索引原理与技术背景》](../201612/20161231_01.md)  
- [《重新发现PostgreSQL之美 - 13 brin 时序索引》](../202106/20210605_02.md)  
- [《PostgreSQL 14 preview - pageinspect 内窥heap,index存储结构 , 新增对gist索引的支持》](../202101/20210113_02.md)  
- [《PostgreSQL 黑科技 - 空间聚集存储, 内窥GIN, GiST, SP-GiST索引》](../201709/20170905_01.md)  
   
3、那么怎么优化呢?    
一页一页的翻, 是有优化方法的.   
   
3\.1、如果SQL不是在pk上order by, 那么可以order by联合PK索引. (对于没有pk的表, 可以增加1个序列(这个序列自动生成, 不变), 作为order by字段的联合UK). 用最后一条的value作为下次的条件输入, 去除offset.    
PS: 加PK或者UK的目的是防止gap.     
   
例子1:   
有PK的表.   
   
```   
create unlogged table a (id serial8 primary key, info text, crt_time timestamp);    
insert into a (info,crt_time) select 'test', clock_timestamp() from generate_series(1,1000000);   
```   
   
问题SQL:    
使用offset翻页   
   
```   
create index idx_a_1 on a (info,crt_time);   
select * from a where info='?' order by crt_time limit 10 offset 100;    
   
-- limit 10 offset 100 扫描了110行   
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from a where info='test' order by crt_time limit 10 offset 100;   
                                                             QUERY PLAN                                                                 
-------------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=3.26..3.55 rows=10 width=21) (actual time=0.072..0.078 rows=10 loops=1)   
   Output: id, info, crt_time   
   Buffers: shared hit=4   
   ->  Index Scan using idx_a_1 on public.a  (cost=0.42..28387.47 rows=1000000 width=21) (actual time=0.031..0.062 rows=110 loops=1)   
         Output: id, info, crt_time   
         Index Cond: (a.info = 'test'::text)   
         Buffers: shared hit=4   
 Planning:   
   Buffers: shared hit=28   
 Planning Time: 0.473 ms   
 Execution Time: 0.101 ms   
(11 rows)   
```   
   
优化:   
联合PK进行排序, 使用上一次翻页的最后一条, 作为临界条件传入下一次where条件中, 从而避免使用offset.      
   
```   
create index idx_a_2 on a (info,crt_time,id);    
select * from a where info=? and crt_time>=? and id>? order by crt_time,id limit 10 ;   
   
postgres=# select * from a where info='test' and crt_time>='2021-12-20 12:23:38.403651' and id>1 order by crt_time,id limit 10 ;   
   id    | info |          crt_time             
---------+------+----------------------------   
 1000102 | test | 2021-12-20 12:23:38.403651   
 1000103 | test | 2021-12-20 12:23:38.403671   
 1000104 | test | 2021-12-20 12:23:38.403673   
 1000105 | test | 2021-12-20 12:23:38.403675   
 1000106 | test | 2021-12-20 12:23:38.403677   
 1000107 | test | 2021-12-20 12:23:38.403678   
 1000108 | test | 2021-12-20 12:23:38.40368   
 1000109 | test | 2021-12-20 12:23:38.403683   
 1000110 | test | 2021-12-20 12:23:38.403685   
 1000111 | test | 2021-12-20 12:23:38.403687   
(10 rows)   
   
postgres=# select * from a where info='test' and crt_time>='2021-12-20 12:23:38.403687' and id>1000111 order by crt_time,id limit 10 ;   
   id    | info |          crt_time             
---------+------+----------------------------   
 1000112 | test | 2021-12-20 12:23:38.403689   
 1000113 | test | 2021-12-20 12:23:38.403691   
 1000114 | test | 2021-12-20 12:23:38.403693   
 1000115 | test | 2021-12-20 12:23:38.403695   
 1000116 | test | 2021-12-20 12:23:38.403696   
 1000117 | test | 2021-12-20 12:23:38.403698   
 1000118 | test | 2021-12-20 12:23:38.4037   
 1000119 | test | 2021-12-20 12:23:38.403715   
 1000120 | test | 2021-12-20 12:23:38.403717   
 1000121 | test | 2021-12-20 12:23:38.403719   
(10 rows)   
   
-- 使用上次的条件作为下次的临界条件, limit 10只需要扫描10行   
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from a    
where info='test' and crt_time>='2021-12-20 12:23:38.403687' and id>1000111    
order by crt_time, id limit 10 ;   
                                                                    QUERY PLAN                                                                       
--------------------------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=0.42..0.70 rows=10 width=21) (actual time=0.032..0.038 rows=10 loops=1)   
   Output: id, info, crt_time   
   Buffers: shared hit=4   
   ->  Index Only Scan using idx_a_2 on public.a  (cost=0.42..27946.47 rows=999789 width=21) (actual time=0.030..0.033 rows=10 loops=1)   
         Output: id, info, crt_time   
         Index Cond: ((a.info = 'test'::text) AND (a.crt_time >= '2021-12-20 12:23:38.403687'::timestamp without time zone) AND (a.id > 1000111))   
         Heap Fetches: 0   
         Buffers: shared hit=4   
 Planning:   
   Buffers: shared hit=4   
 Planning Time: 0.196 ms   
 Execution Time: 0.062 ms   
(12 rows)   
```   
   
例子2:   
没有PK、UK的表.    
   
```   
create unlogged table b (info text, crt_time timestamp, c1 int);      
insert into b (info,crt_time, c1) select 'test', clock_timestamp(), random()*100 from generate_series(1,1000000);   
```   
   
问题SQL:   
使用offset翻页.   
   
```   
create index idx_b_1 on b (info, c1);   
select * from b where info =? order by c1 limit 10 offset 100;    
   
postgres=# select * from b where info ='test' order by c1 limit 10 offset 1000;    
 info |          crt_time          | c1    
------+----------------------------+----   
 test | 2021-12-20 13:46:11.975846 |  0    
 test | 2021-12-20 13:46:11.975895 |  0    
 test | 2021-12-20 13:46:11.976153 |  0    
 test | 2021-12-20 13:46:11.976212 |  0    
 test | 2021-12-20 13:46:11.976319 |  0    
 test | 2021-12-20 13:46:11.976413 |  0    
 test | 2021-12-20 13:46:11.976444 |  0    
 test | 2021-12-20 13:46:11.97667  |  0    
 test | 2021-12-20 13:46:11.977002 |  0    
 test | 2021-12-20 13:46:11.977111 |  0    
(10 rows)   
   
-- limit 10 offset 1000 扫描了1010行   
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from b where info ='test' order by c1 limit 10 offset 1000;    
                                                              QUERY PLAN                                                                 
--------------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=26.56..26.82 rows=10 width=25) (actual time=0.992..1.006 rows=10 loops=1)   
   Output: info, crt_time, c1, uk   
   Buffers: shared hit=716   
   ->  Index Scan using idx_b_1 on public.b  (cost=0.42..26131.08 rows=1000000 width=25) (actual time=0.034..0.909 rows=1010 loops=1)   
         Output: info, crt_time, c1, uk   
         Index Cond: (b.info = 'test'::text)   
         Buffers: shared hit=716   
 Planning Time: 0.112 ms   
 Execution Time: 1.027 ms   
(9 rows)   
```   
   
优化:   
新建一个字段, 存储序列值防止重复, 联合这个序列值进行排序, 使用上一次翻页的最后一条, 作为临界条件传入下一次where条件中, 从而避免使用offset.      
   
```   
alter table b add column uk serial8;  -- 注意会rewrite table. 大表慎重.   
-- 如果想在逻辑层面确保唯一, 可以再加个唯一约束. 但是会增加索引开销. 看业务需求再做决定   
-- create unique index idx_b_uk on b (uk);   
create index idx_b_2 on b (info, c1, uk);    
select * from a where info=? and c1>=? and uk>? order by c1,uk limit 10 ;   
   
-- 先不用优化SQL查询一下    
postgres=# select * from b where info ='test' order by c1,uk limit 10 offset 1000;    
 info |          crt_time          | c1 |   uk      
------+----------------------------+----+--------   
 test | 2021-12-20 13:46:11.975846 |  0 | 210694   
 test | 2021-12-20 13:46:11.975895 |  0 | 210707   
 test | 2021-12-20 13:46:11.976153 |  0 | 211162   
 test | 2021-12-20 13:46:11.976212 |  0 | 211219   
 test | 2021-12-20 13:46:11.976319 |  0 | 211385   
 test | 2021-12-20 13:46:11.976413 |  0 | 211531   
 test | 2021-12-20 13:46:11.976444 |  0 | 211599   
 test | 2021-12-20 13:46:11.97667  |  0 | 211880   
 test | 2021-12-20 13:46:11.977002 |  0 | 212354   
 test | 2021-12-20 13:46:11.977111 |  0 | 212528   
(10 rows)    
   
-- limit 10 offset 1000 扫描了1010行   
postgres=# explain (analyze,verbose,timing,costs,buffers)   
postgres-# select * from b where info ='test' order by c1,uk limit 10 offset 1000;    
                                                              QUERY PLAN                                                                 
--------------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=31.06..31.36 rows=10 width=25) (actual time=1.181..1.195 rows=10 loops=1)   
   Output: info, crt_time, c1, uk   
   Buffers: shared hit=720   
   ->  Index Scan using idx_b_2 on public.b  (cost=0.42..30632.28 rows=1000000 width=25) (actual time=0.033..1.070 rows=1010 loops=1)   
         Output: info, crt_time, c1, uk   
         Index Cond: (b.info = 'test'::text)   
         Buffers: shared hit=720   
 Planning Time: 0.112 ms   
 Execution Time: 1.221 ms   
(9 rows)   
   
-- 优化SQL如下   
postgres=# select * from b where info='test' and c1>=0 and uk>212528 order by c1,uk limit 10 ;   
 info |          crt_time          | c1 |   uk      
------+----------------------------+----+--------   
 test | 2021-12-20 13:46:11.977324 |  0 | 212835   
 test | 2021-12-20 13:46:11.97776  |  0 | 213058   
 test | 2021-12-20 13:46:11.97831  |  0 | 213454   
 test | 2021-12-20 13:46:11.978551 |  0 | 213641   
 test | 2021-12-20 13:46:11.978914 |  0 | 213871   
 test | 2021-12-20 13:46:11.979195 |  0 | 214152   
 test | 2021-12-20 13:46:11.979217 |  0 | 214179   
 test | 2021-12-20 13:46:11.979622 |  0 | 214469   
 test | 2021-12-20 13:46:11.980445 |  0 | 215447   
 test | 2021-12-20 13:46:11.980464 |  0 | 215488   
(10 rows)   
   
-- 使用上次的条件作为下次的临界条件, limit 10只需要扫描10行   
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from b where info='test' and c1>=0 and uk>212528 order by c1,uk limit 10 ;   
                                                            QUERY PLAN                                                                
-----------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=0.42..1.21 rows=10 width=25) (actual time=0.027..0.072 rows=10 loops=1)   
   Output: info, crt_time, c1, uk   
   Buffers: shared hit=12   
   ->  Index Scan using idx_b_2 on public.b  (cost=0.42..26206.70 rows=333301 width=25) (actual time=0.026..0.068 rows=10 loops=1)   
         Output: info, crt_time, c1, uk   
         Index Cond: ((b.info = 'test'::text) AND (b.c1 >= 0) AND (b.uk > 212528))   
         Buffers: shared hit=12   
 Planning Time: 0.134 ms   
 Execution Time: 0.097 ms   
(9 rows)   
```   
   
3\.2、如果不想加1个UK来防止返回值的gap, 可以使用PG的新特性fetch ties.  (但是注意: 如果某个value的重复值非常多, gang会很大很大, 有一定风险, 例如可能打爆客户端内存.)     
[《PostgreSQL 13 offset fetch first with ties - 返回ordered peer行S》](../202005/20200528_01.md)     
   
例子1:   
   
```   
create unlogged table c (info text, crt_time timestamp, c1 int);      
insert into c (info,crt_time, c1) select 'test', clock_timestamp(), random()*100 from generate_series(1,1000000);   
```   
   
问题SQL:    
   
```   
create index idx_c_1 on c (info, c1);    
select * from c where info=? order by c1 limit 10 offset 1000 ;    
   
postgres=# select * from c where info='test' order by c1 limit 10 offset 1000 ;    
 info |          crt_time          | c1    
------+----------------------------+----   
 test | 2021-12-20 13:56:32.740037 |  0   
 test | 2021-12-20 13:56:32.74006  |  0   
 test | 2021-12-20 13:56:32.740173 |  0   
 test | 2021-12-20 13:56:32.740293 |  0   
 test | 2021-12-20 13:56:32.740364 |  0   
 test | 2021-12-20 13:56:32.74052  |  0   
 test | 2021-12-20 13:56:32.740723 |  0   
 test | 2021-12-20 13:56:32.741196 |  0   
 test | 2021-12-20 13:56:32.741273 |  0   
 test | 2021-12-20 13:56:32.741303 |  0   
(10 rows)   
```   
   
优化:    
   
```   
-- 使用上次的条件作为下次的临界条件, 同时为了防止gap, 返还所有order by的字段最后1条的value相同的所有行.    
-- 这里c1=1有10023行, 全部返回. 扫描了10024行, 即判断第10024行发现c1的值不是1了, 说明已全部返回.    
   
select * from c where info='test' and c1 > ? order by c1 fetch first 10 row with ties;    
   
select * from c where info='test' and c1 > 0 order by c1 fetch first 10 row with ties;    
   
...   
 test | 2021-12-20 13:56:33.289016 |  1   
 test | 2021-12-20 13:56:33.289023 |  1   
 test | 2021-12-20 13:56:33.289037 |  1   
(10023 rows)   
   
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from c where info='test' and c1 > 0 order by c1 fetch first 10 row with ties;    
                                                              QUERY PLAN                                                                 
--------------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=0.42..0.70 rows=10 width=17) (actual time=0.034..10.198 rows=10023 loops=1)   
   Output: info, crt_time, c1   
   Buffers: shared hit=5064   
   ->  Index Scan using idx_c_1 on public.c  (cost=0.42..27480.01 rows=994867 width=17) (actual time=0.033..7.837 rows=10024 loops=1)   
         Output: info, crt_time, c1   
         Index Cond: ((c.info = 'test'::text) AND (c.c1 > 0))   
         Buffers: shared hit=5064   
 Planning Time: 0.118 ms   
 Execution Time: 11.191 ms   
(9 rows)   
   
-- 再取翻页的就取c1>1的了.    
postgres=#        explain (analyze,verbose,timing,costs,buffers) select * from c where info='test' and c1 > 1 order by c1 fetch first 10 row with ties;    
                                                              QUERY PLAN                                                                 
--------------------------------------------------------------------------------------------------------------------------------------   
 Limit  (cost=0.42..0.70 rows=10 width=17) (actual time=0.023..10.740 rows=10241 loops=1)   
   Output: info, crt_time, c1   
   Buffers: shared hit=5160 read=8   
   ->  Index Scan using idx_c_1 on public.c  (cost=0.42..27230.51 rows=984715 width=17) (actual time=0.022..8.970 rows=10242 loops=1)   
         Output: info, crt_time, c1   
         Index Cond: ((c.info = 'test'::text) AND (c.c1 > 1))   
         Buffers: shared hit=5160 read=8   
 Planning Time: 0.112 ms   
 Execution Time: 11.442 ms   
(9 rows)   
```   
   
4、直接跳到第N页? 没法优化.    
- 因为前面的临界值已经不知道了, 只能offset, 没有办法优化.     
  
参考:  
- [《PostgreSQL 分页, offset, 返回顺序, 扫描方法原理(seqscan, index scan, index only scan, bitmap scan, parallel xx scan)，游标》](../201902/20190228_01.md)  
- [《PostgreSQL 范围过滤 + 其他字段排序OFFSET LIMIT(多字段区间过滤)的优化与加速》](../201801/20180122_02.md)  
- [《PostgreSQL 索引扫描offset内核优化 - case》](../201607/20160717_01.md)  
- [《PostgreSQL 数据访问 offset 的质变 case》](../201607/20160715_02.md)  
- [《论count与offset使用不当的罪名 和 分页的优化》](../201605/20160506_01.md)  
- [《PostgreSQL offset 原理，及使用注意事项》](../201604/20160402_02.md)  
- [《分页优化 - order by limit x offset y performance tuning》](../201402/20140211_01.md)  
- [《PostgreSQL 13 offset fetch first with ties - 返回ordered peer行S》](../202005/20200528_01.md)  
  
    
#### 10、为什么有的索引不支持字符串前置查询? (patten, lc_collate)       
    
11、为什么count查询慢?       
    
12、为什么SQL会自动启用并行计算?     
    
13、为什么长时间等待业务处理的情况不建议封装在事务中?       
    
14、为什么会有死锁?       
    
15、为什么业务开启多会话并行后反而慢?    (死锁, 等待, 业务逻辑处理有问题)      
    
16、为什么说有些排序操作建议让业务来做?     
    
17、为什么说有些逻辑应该交给数据库存储过程来做?   (短平快高频多次交互)    
    
18、为什么性能差? 如何找到捣蛋鬼SQL?    (top sql)      
    
19、为什么SQL性能会抖动?    (P99 , 资源争抢, 锁等待, 执行计划抖动...)      
    
20、为什么分区表的分区过多会导致性能下降?      
    
21、为什么要用绑定变量?   (安全、短平快)       
    
22、为什么创建索引会堵塞DML?  如何在线创建索引?      
    
23、为什么有的函数不能被用来创建表达式索引?     (stable, volatile)        
    
24、为什么与检索字段类型不一致的输入条件有时可能不能采用索引?        
    
    
## 备份、订阅、恢复    
    
1、为什么逻辑复制在主从切换后会丢数据?         
    
2、为什么有备份但是不能恢复到指定时间点?   (时区指定有问题、目标时间早于全量备份到逻辑一致位点)       
    
3、为什么逻辑备份可能和业务产生冲突?       
    
4、为什么逻辑备份可能导致实例膨胀?       
    
    
## 从库    
    
1、为什么在从库上跑长事务或长SQL可能会报错?      
    
2、为什么从库会出现回放延迟?      
    
3、为什么主备切换后并不总是需要重建HA或重建灾难备份库?      
    
4、为什么有时从库会报上游WAL日志已删除的错误?      
    
    
## 性能、管理    
    
1、为什么默认配置性能比较差?      
    
2、为什么要关闭NUMA?       
    
3、为什么高并发的短链接性能会很差?      
    
4、为什么会发生OOM?         (adj 防止 https://github.com/digoal/blog/blob/master/201801/20180121_01.md)      
    
5、为什么存在内存浪费严重的现象?   (relcache, 分区表, 内存霸占, 未开启huge page页表浪费)      
    
6、为什么在操作系统直接kill 数据库进程会导致数据库重启?      
    
7、为什么会出现数据库块损坏?      
    
8、为什么存在与业务无关的突发IO和CPU飙升?     
    
9、为什么存在与业务无关的持续IO与CPU消耗?     
    
10、为什么表会膨胀?            (https://github.com/digoal/blog/blob/master/201801/20180121_01.md)    
    
11、为什么索引会膨胀?         
    
12、为什么垃圾回收有时不起作用?       
    
13、为什么log日志量暴增而且影响性能?  (审计, pipeline buffer, 使用采样日志)       
    
14、为什么WAL日志会堆积?       (https://github.com/digoal/blog/blob/master/201801/20180121_01.md)    
    
15、为什么WAL会突然暴增?      
    
16、为什么数据文件会突然暴增?      (递归死循环、某些大的查询可能导致临时文件的大量产生  https://github.com/digoal/blog/blob/master/201801/20180121_01.md)    
    
17、为什么会出现雪崩?      
    
18、为什么大量delete后表和索引的空间没有变小?   (高水位)      
    
19、如何在线降低表、索引水位?      
    
20、为什么push|pull大量数据的读写比较慢?     (COPY, pipeline模式)      
    
21、怎么判断数据库有没有瓶颈?  (处理能力有没有到顶? 还能支撑多大的业务增长?)       
    
22、如何发现过去、现在、未来的性能问题?      
    
23、为什么SQL执行计划不正确?     
    
## 业务    
1、为什么时序类搜索可能有IO放大，除了 cpu,io,net 还有哪些隐藏的瓶颈，为什么要聚集?    
    
2、为什么空间搜索有IO放大，为什么要数据聚集， 为什么要分裂查询?     
    
3、为什么有时索引扫描并不比全表扫描更快?      
    
4、为什么GIN有时不快?        
    
5、为什么BRIN有时不快?        
  
6、为什么输入顺序会影响最终GiST创建出来的索引性能?  
    
7、有几种索引、该如何选择索引?        
  
8、为什么当前还不建议频繁使用临时表?   
    
## 安全    
1、为什么会有SQL注入?       
    
2、为什么赋予了select权限依旧无权查询表? (逻辑结构)     
- 怎么赋予默认只读权限    
- 怎么赋予默认写权限    
- 怎么赋予新增表的默认权限    
- 怎么赋予已有表的默认权限    
    
3、为什么事务号会耗尽?      
    
4、为什么慢SQL，空闲事务，长事务，2PC，慢SLOT，standby feedback，强制vacuum age defer都存在风险    
    
    
  
#### [期望 PostgreSQL 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [类似Oracle RAC架构的PostgreSQL已开源: 阿里云PolarDB for PostgreSQL云原生分布式开源数据库!](https://github.com/ApsaraDB/PolarDB-for-PostgreSQL "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
